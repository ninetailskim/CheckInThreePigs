paddle的resize的写法

```python
def det_resize_image(im, max_side_len=960):
    h, w, _ = im.shape

    resize_w = w
    resize_h = h

    # limit the max side
    if max(resize_h, resize_w) > max_side_len:
        if resize_h > resize_w:
            ratio = float(max_side_len) / resize_h
        else:
            ratio = float(max_side_len) / resize_w
    else:
        ratio = 1.
    resize_h = int(resize_h * ratio)
    resize_w = int(resize_w * ratio)
    if resize_h % 32 == 0:
        resize_h = resize_h
    elif resize_h // 32 <= 1:
        resize_h = 32
    else:
        resize_h = (resize_h // 32 - 1) * 32
    if resize_w % 32 == 0:
        resize_w = resize_w
    elif resize_w // 32 <= 1:
        resize_w = 32
    else:
        resize_w = (resize_w // 32 - 1) * 32
    if int(resize_w) <= 0 or int(resize_h) <= 0:
        return None, (None, None)
    im = cv2.resize(im, (int(resize_w), int(resize_h)))
    ratio_h = resize_h / float(h)
    ratio_w = resize_w / float(w)
    return im, (ratio_h, ratio_w)
```

---

使用Paddle Inference API进行推理：

1） 配置推理选项。在使用Paddle Inference推理部署过程中，我们通过AnalysisConfig对配置推理的相关参数，包括不限于对设备的配置（CPU/GPU），模型路径的设置，是否开启图优化，内存/显存优化等。

2） 创建AnalysisPredictor。根据设定好的AnalysisConfig创建推理引擎predictor，创建期间会进行模型加载，分析优化等工作。

3） 准备输入数据。获取模型的所有输入tensor，并将数据设置到tensor中。

4） 运行推理。

5） 获取模型输出。拿到模型的所有输出tensor，并获取tensor中的数值。

---

Q-learning

$Q(s,a)\leftarrow(1-\alpha)Q(s,a)+\alpha(r+\gamma \max\limits_{a}Q(s',a'))$

在s'上选择产生最大期望的动作a'，但是在真正到达s'的时候，并不是一定要选择a'。在s处选择a，拿到奖励r，到达下一个状态s'。

过程：

初始化Q表

重复：

​	根据Q表在状态S处选择a（贪心用于训练）

​	采取a，观测到奖励r和新状态s'

​	更新Q表，$Q(s,a)\leftarrow(1-\alpha)Q(s,a)+\alpha(r+\gamma \max\limits_{a}Q(s',a'))$

​	更新状态到s'

直到s为终止状态

---

sarsa

$Q(s,a)\leftarrow(1-\alpha)Q(s,a)+\alpha(r+\gamma \max\limits_{a}Q(s',a'))$

公式一样，但是区别在哪

过程:

初始化s

根据Q表在状态S处选择a（贪心用于训练）

重复：

​	执行a，观测到奖励r和新状态s'

​	根据Q表从s'处选择a‘（贪心用于训练）

​	更新Q表，$Q(s,a)\leftarrow(1-\alpha)Q(s,a)+\alpha(r+\gamma \max\limits_{a}Q(s',a'))$

​	更新状态到s'，更新选择a为a’ //也就是说下一次一定会执行这个a‘

直到s为终止状态